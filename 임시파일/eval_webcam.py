import cv2
import numpy as np
import torch
import torchvision.transforms as transforms
from emotion import EmotionNet
from collections import Counter
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import time
import os

# ëª¨ë¸ ë¡œë“œ
device = torch.device("cpu")
model = EmotionNet()

checkpoint = torch.load("model.pth", map_location=device)
model.load_state_dict(checkpoint['model'])
model.eval()

# ê°ì • í´ë˜ìŠ¤
class_labels = ['ê¸°ì¨', 'ë‹¹í™©', 'ë¶„ë…¸', 'ë¶ˆì•ˆ', 'ìƒì²˜', 'ìŠ¬í””', 'ì¤‘ë¦½']
class_labels_dict = {'ê¸°ì¨': 0, 'ë‹¹í™©': 1, 'ë¶„ë…¸': 2,
                     'ë¶ˆì•ˆ': 3, 'ìƒì²˜': 4, 'ìŠ¬í””': 5, 'ì¤‘ë¦½': 6}

# ê¸ì •/ë¶€ì • ê°ì • ì„¸íŠ¸ ì •ì˜
positive_set = {'ê¸°ì¨', 'ë‹¹í™©', 'ì¤‘ë¦½'}
negative_set = {'ìŠ¬í””', 'ë¶ˆì•ˆ', 'ë¶„ë…¸', 'ìƒì²˜'}

# í•œê¸€ í°íŠ¸ ì„¤ì •
def get_font_path():
    """ì‹œìŠ¤í…œì— ì„¤ì¹˜ëœ í•œê¸€ í°íŠ¸ ê²½ë¡œ ë°˜í™˜"""
    # macOS ê¸°ë³¸ í•œê¸€ í°íŠ¸
    font_paths = [
        "/System/Library/Fonts/AppleSDGothicNeo.ttc",  # macOS
        "/System/Library/Fonts/PingFang.ttc",          # macOS
        "/Library/Fonts/NanumGothic.ttf",              # ë‚˜ëˆ”ê³ ë”•
        "/Library/Fonts/MalgunGothic.ttf",             # ë§‘ì€ ê³ ë”•
        "/Library/Fonts/NotoSansCJKkr-Regular.otf"     # Noto Sans
    ]
    
    for path in font_paths:
        if os.path.exists(path):
            return path
    
    return None

def set_korean_font():
    """matplotlibì— í•œê¸€ í°íŠ¸ ì„¤ì •"""
    font_path = get_font_path()
    if font_path:
        # í°íŠ¸ ì„¤ì •
        font_prop = fm.FontProperties(fname=font_path)
        plt.rcParams['font.family'] = font_prop.get_name()
        plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€
        return True
    return False

def put_korean_text(img, text, position, font_size=32, color=(255, 255, 255)):
    """í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ ì´ë¯¸ì§€ì— ê·¸ë¦¬ëŠ” í•¨ìˆ˜"""
    # PIL Imageë¡œ ë³€í™˜
    img_pil = Image.fromarray(img)
    draw = ImageDraw.Draw(img_pil)
    
    # í°íŠ¸ ì„¤ì •
    font_path = get_font_path()
    if font_path:
        try:
            font = ImageFont.truetype(font_path, font_size)
        except:
            font = ImageFont.loadDefault()
    else:
        font = ImageFont.loadDefault()
        print("âš ï¸ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
    draw.text(position, text, font=font, fill=color)
    
    # OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    return np.array(img_pil)

class WebcamEmotionAnalyzer:
    def __init__(self):
        self.results = []
        self.frame_count = 0
        self.start_time = None
        
        # ê°ì • ê°€ì¤‘ì¹˜ (ë©´ì ‘ ìƒí™©ì— ë§ê²Œ ì¡°ì •)
        self.emotion_weights = {
            "ê¸°ì¨": 80,       # ê¸ì •ì  (ì ì ˆí•œ ë¯¸ì†Œ)
            "ì¤‘ë¦½": 70,       # ì¤‘ë¦½ì  (ì•½ê°„ì˜ ê¸ì •ì ìˆ˜)
            "ë‹¹í™©": 35,       # ë¶€ì •ì  (ë©´ì ‘ì—ì„œ ì¢‹ì§€ ì•ŠìŒ)
            "ìŠ¬í””": 30,       # ë¶€ì •ì 
            "ë¶„ë…¸": 40,       # ë¶€ì •ì 
            "ë¶ˆì•ˆ": 30,       # ë¶€ì •ì 
            "ìƒì²˜": 30        # ë¶€ì •ì 
        }

        # í‰ê°€ ê¸°ì¤€ ì„ê³„ê°’ (ë©´ì ‘ ìƒí™©ì— ë§ê²Œ ì¡°ì •)
        self.thresholds = {
            'neutral_ratio': 0.5,      # ì¤‘ë¦½ í‘œì • ë¹„ìœ¨ (ê°€ì¥ ì¤‘ìš”)
            'positive_ratio': 0.3,     # ê¸ì •ì  í‘œì • ë¹„ìœ¨ (ê¸°ì¨)
            'negative_ratio': 0.2,     # ë¶€ì •ì  í‘œì • ë¹„ìœ¨ (ìµœì†Œí™”)
            'confidence_threshold': 0.6, # ì‹ ë¢°ë„ ì„ê³„ê°’
            'happy_threshold': 0.2      # ê¸°ì¨ ê°ì • ìµœì†Œ ë¹„ìœ¨
        }

        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        self.transform = transforms.Compose([
            transforms.Grayscale(num_output_channels=1),
            transforms.Resize((48, 48)),
            transforms.ToTensor(),
        ])

        # í°íŠ¸ í¬ê¸° ì„¤ì •
        self.font_sizes = {
            'main': 32,    # ì£¼ìš” ê°ì • í‘œì‹œ
            'sub': 24,     # í™•ë¥  í‘œì‹œ
            'info': 20     # ê¸°íƒ€ ì •ë³´
        }

    def analyze_webcam(self):
        """ì›¹ìº  ì‹¤ì‹œê°„ ê°ì • ë¶„ì„"""
        print("ì›¹ìº  ì´ˆê¸°í™” ì¤‘...")
        
        # ì›¹ìº  ì¥ì¹˜ 1ë²ˆìœ¼ë¡œ ì§ì ‘ ì§€ì •
        cap = cv2.VideoCapture(1)  # 0 â†’ 1ë¡œ ë³€ê²½
        
        if not cap.isOpened():
            print("âŒ ì›¹ìº (1ë²ˆ)ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
            print("1. ì›¹ìº ì´ ì»´í“¨í„°ì— ì œëŒ€ë¡œ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€")
            print("2. ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì—ì„œ ì›¹ìº ì„ ì‚¬ìš© ì¤‘ì´ ì•„ë‹Œì§€")
            print("3. ì›¹ìº  ê¶Œí•œì´ í—ˆìš©ë˜ì–´ ìˆëŠ”ì§€")
            return None

        # ì›¹ìº  ì„¤ì • í™•ì¸
        width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
        height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        print(f"ì›¹ìº  ì„¤ì •: {width}x{height} @ {fps}fps")
        
        if width == 0 or height == 0:
            print("âŒ ì›¹ìº  í•´ìƒë„ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            cap.release()
            return None

        self.start_time = time.time()
        self.frame_count = 0
        
        print("\nì›¹ìº  ë¶„ì„ ì‹œì‘ (ì¢…ë£Œí•˜ë ¤ë©´ 'q'ë¥¼ ëˆ„ë¥´ì„¸ìš”)")
        print("=" * 50)

        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    print("âŒ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    break

                # í”„ë ˆì„ í¬ê¸° í™•ì¸
                if frame.size == 0:
                    print("âŒ ë¹ˆ í”„ë ˆì„ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    break

                # BGR to RGB ë³€í™˜
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                image = Image.fromarray(rgb_frame)
                input_tensor = self.transform(image).unsqueeze(0)

                # ê°ì • ì˜ˆì¸¡
                with torch.no_grad():
                    output = model(input_tensor)
                    probs = torch.nn.functional.softmax(output, dim=1)[0]
                    
                    # ëª¨ë“  ê°ì •ì˜ í™•ë¥ 
                    all_probs = {emotion: float(prob) for emotion, prob in zip(class_labels, probs)}
                    
                    # ìµœê³  í™•ë¥ ì˜ ê°ì •
                    pred_idx = torch.argmax(probs).item()
                    pred_label = class_labels[pred_idx]
                    confidence = probs[pred_idx].item()

                # ê²°ê³¼ ì €ì¥
                current_time = time.time() - self.start_time
                self.results.append({
                    'timestamp': current_time,
                    'emotion': pred_label,
                    'confidence': confidence,
                    'all_probs': all_probs
                })
                self.frame_count += 1

                # í™”ë©´ì— í‘œì‹œí•  í…ìŠ¤íŠ¸ (í•œê¸€)
                emotion_text = f"ê°ì •: {pred_label} ({confidence:.2f})"
                frame = put_korean_text(frame, emotion_text, (10, 30), 
                                      self.font_sizes['main'], (0, 255, 0))
                
                # ëª¨ë“  ê°ì •ì˜ í™•ë¥  í‘œì‹œ (í•œê¸€)
                y_pos = 70
                for emotion, prob in all_probs.items():
                    prob_text = f"{emotion}: {prob:.2f}"
                    frame = put_korean_text(frame, prob_text, (10, y_pos),
                                          self.font_sizes['sub'], (255, 255, 255))
                    y_pos += 30

                # í”„ë ˆì„ í‘œì‹œ
                cv2.imshow('ê°ì • ë¶„ì„', frame)  # ì°½ ì œëª©ë„ í•œê¸€ë¡œ ë³€ê²½

                # 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    print("\nì‚¬ìš©ìê°€ ë¶„ì„ì„ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤.")
                    break

        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        finally:
            cap.release()
            cv2.destroyAllWindows()
            
            if self.frame_count > 0:
                print(f"\në¶„ì„ ì™„ë£Œ: {self.frame_count}ê°œ í”„ë ˆì„ ë¶„ì„")
                return self.results
            else:
                print("\nâŒ ë¶„ì„ëœ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤.")
                return None

    def calculate_metrics(self):
        """ë¶„ì„ ì§€í‘œ ê³„ì‚°"""
        if not self.results:
            return None

        emotions = [r['emotion'] for r in self.results]
        confidences = [r['confidence'] for r in self.results]
        total_samples = len(emotions)

        # ê° ê°ì •ë³„ ë¹„ìœ¨ ê³„ì‚°
        emotion_ratios = {}
        for emotion in class_labels:
            count = emotions.count(emotion)
            emotion_ratios[emotion] = count / total_samples

        # ê¸°ë³¸ ë¹„ìœ¨ ê³„ì‚°
        neutral_count = emotions.count("ì¤‘ë¦½")
        happy_count = emotions.count("ê¸°ì¨")
        negative_count = sum(1 for e in emotions if e not in {"ì¤‘ë¦½", "ê¸°ì¨"})

        neutral_ratio = neutral_count / total_samples
        happy_ratio = happy_count / total_samples
        negative_ratio = negative_count / total_samples

        # ê°ì • ì „ì´ ë¶„ì„ (ë©´ì ‘ ìƒí™©ì— ë§ê²Œ ì¡°ì •)
        transitions = []
        for i in range(1, len(emotions)):
            prev_emotion = emotions[i-1]
            curr_emotion = emotions[i]
            
            # ìì—°ìŠ¤ëŸ¬ìš´ ì „ì´ì¸ì§€ í‰ê°€
            prev_weight = self.emotion_weights[prev_emotion]
            curr_weight = self.emotion_weights[curr_emotion]
            
            # ê¸‰ê²©í•œ ë³€í™” íŒë‹¨ (30ì  ì´ìƒ ì°¨ì´ë‚˜ë©´ ê¸‰ê²©í•œ ë³€í™”ë¡œ íŒë‹¨)
            if abs(prev_weight - curr_weight) > 30:
                transitions.append('abrupt')
            else:
                transitions.append('natural')

        abrupt_transition_ratio = transitions.count('abrupt') / len(transitions) if transitions else 0
        
        # ì•ˆì •ì„± ì ìˆ˜ (ì¤‘ë¦½ê³¼ ê¸°ì¨ì´ ì–¼ë§ˆë‚˜ ì•ˆì •ì ìœ¼ë¡œ ìœ ì§€ë˜ëŠ”ì§€)
        stability_score = 0
        if neutral_ratio >= self.thresholds['neutral_ratio']:
            stability_score += 0.6
        if happy_ratio >= self.thresholds['happy_threshold']:
            stability_score += 0.4

        # ì‹ ë¢°ë„ ë¶„ì„
        avg_confidence = np.mean(confidences)
        low_confidence_ratio = sum(1 for c in confidences if c < self.thresholds['confidence_threshold']) / total_samples

        # ë¶€ì •ì  ê°ì • ë¶„ì„
        negative_emotions = [e for e in emotions if e not in {"ì¤‘ë¦½", "ê¸°ì¨"}]
        negative_ratio = len(negative_emotions) / total_samples

        return {
            'emotion_ratios': emotion_ratios,
            'neutral_ratio': neutral_ratio,
            'happy_ratio': happy_ratio,
            'negative_ratio': negative_ratio,
            'abrupt_transition_ratio': abrupt_transition_ratio,
            'stability_score': stability_score,
            'avg_confidence': avg_confidence,
            'low_confidence_ratio': low_confidence_ratio
        }

    def generate_assessment(self):
        """ì¢…í•© í‰ê°€ ìƒì„±"""
        metrics = self.calculate_metrics()
        if not metrics:
            return {
                'overall_score': 0,
                'grade': 'C',
                'key_findings': ["ë¶„ì„ ë°ì´í„° ë¶€ì¡±"],
                'recommendations': []
            }

        assessment = {
            'overall_score': 0,
            'grade': 'C',
            'key_findings': [],
            'recommendations': []
        }

        # 1. ê¸°ë³¸ ì ìˆ˜ ê³„ì‚° (ë©´ì ‘ ìƒí™©ì— ë§ê²Œ ì¡°ì •)
        base_score = (
            metrics['neutral_ratio'] * 40 +     # ì¤‘ë¦½ í‘œì • (ê°€ì¥ ì¤‘ìš”)
            metrics['happy_ratio'] * 30 +       # ê¸°ì¨ í‘œì •
            metrics['stability_score'] * 20 +   # ì•ˆì •ì„±
            (1 - metrics['negative_ratio']) * 10  # ë¶€ì •ì  ê°ì • ìµœì†Œí™”
        )

        # 2. ê°ì  ìš”ì†Œ ì ìš©
        penalties = 0
        
        # ê¸‰ê²©í•œ ê°ì • ë³€í™”ì— ëŒ€í•œ ê°ì 
        if metrics['abrupt_transition_ratio'] > 0.2:
            penalties += 5
            assessment['key_findings'].append("â–³ ê°ì • ë³€í™”ê°€ ë‹¤ì†Œ ê¸‰ê²©í•¨")
        
        # ë¶€ì •ì  ê°ì •ì´ ë„ˆë¬´ ë§ì€ ê²½ìš°
        if metrics['negative_ratio'] > self.thresholds['negative_ratio']:
            penalties += 10
            assessment['key_findings'].append("âš  ë¶€ì •ì ì¸ í‘œì •ì´ ë‹¤ì†Œ ë§ìŒ")
        
        # ì‹ ë¢°ë„ê°€ ë‚®ì€ ê²½ìš°
        if metrics['low_confidence_ratio'] > 0.4:
            penalties += 5
            assessment['key_findings'].append("â–³ í‘œì • ì¸ì‹ì´ ë¶ˆì•ˆì •í•¨")

        # 3. ìµœì¢… ì ìˆ˜ ê³„ì‚°
        final_score = max(0, min(100, base_score - penalties))
        assessment['overall_score'] = round(final_score, 1)

        # 4. ë“±ê¸‰ íŒì •
        if final_score >= 75:
            assessment['grade'] = 'A'
            assessment['key_findings'].append("âœ“ ë©´ì ‘ì— ì í•©í•œ í‘œì • ê´€ë¦¬")
        elif final_score >= 60:
            assessment['grade'] = 'B'
            assessment['key_findings'].append("â—‹ ëŒ€ì²´ë¡œ ì ì ˆí•œ í‘œì •")
        else:
            assessment['grade'] = 'C'
            assessment['key_findings'].append("â–³ í‘œì • ê´€ë¦¬ ê°œì„  í•„ìš”")

        # 5. êµ¬ì²´ì ì¸ ê¶Œì¥ì‚¬í•­ ìƒì„±
        if metrics['neutral_ratio'] < self.thresholds['neutral_ratio']:
            assessment['recommendations'].append("â€¢ ì¤‘ë¦½ì ì¸ í‘œì •ì„ ë” ìœ ì§€í•´ë³´ì„¸ìš”")
        if metrics['happy_ratio'] < self.thresholds['happy_threshold']:
            assessment['recommendations'].append("â€¢ ì ì ˆí•œ ë¯¸ì†Œë¥¼ ë” í‘œí˜„í•´ë³´ì„¸ìš”")
        if metrics['negative_ratio'] > self.thresholds['negative_ratio']:
            assessment['recommendations'].append("â€¢ ë¶€ì •ì ì¸ í‘œì •ì„ ì¤„ì—¬ë³´ì„¸ìš”")
        if metrics['abrupt_transition_ratio'] > 0.2:
            assessment['recommendations'].append("â€¢ í‘œì • ë³€í™”ë¥¼ ë” ìì—°ìŠ¤ëŸ½ê²Œ í•´ë³´ì„¸ìš”")
        if metrics['low_confidence_ratio'] > 0.4:
            assessment['recommendations'].append("â€¢ í‘œì •ì„ ë” ëª…í™•í•˜ê²Œ í‘œí˜„í•´ë³´ì„¸ìš”")

        return assessment

    def create_analysis_chart(self):
        """ë¶„ì„ ê²°ê³¼ ì‹œê°í™”"""
        if not self.results:
            return

        # í•œê¸€ í°íŠ¸ ì„¤ì •
        if not set_korean_font():
            print("âš ï¸ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì°¨íŠ¸ì˜ í•œê¸€ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        metrics = self.calculate_metrics()
        
        # 1. ê°ì • ë¶„í¬ íŒŒì´ ì°¨íŠ¸
        emotions = [r['emotion'] for r in self.results]
        emotion_counts = Counter(emotions)
        
        # ê°ì •ì„ ê¸ì •/ì¤‘ë¦½/ë¶€ì •ìœ¼ë¡œ ê·¸ë£¹í™”
        grouped_data = {
            'ê¸ì •': emotion_counts.get('ê¸°ì¨', 0),
            'ì¤‘ë¦½': emotion_counts.get('ì¤‘ë¦½', 0),
            'ë¶€ì •': sum(emotion_counts.get(e, 0) for e in ['ë‹¹í™©', 'ìŠ¬í””', 'ë¶„ë…¸', 'ë¶ˆì•ˆ', 'ìƒì²˜'])
        }

        # ì°¨íŠ¸ ìŠ¤íƒ€ì¼ ì„¤ì •
        plt.style.use('default')
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('ë©´ì ‘ í‘œì • ë¶„ì„ ê²°ê³¼', fontsize=16, y=0.95)  # pad â†’ yë¡œ ë³€ê²½
        
        # ë°°ê²½ìƒ‰ ì„¤ì •
        fig.patch.set_facecolor('#f0f0f0')
        for ax in [ax1, ax2, ax3, ax4]:
            ax.set_facecolor('white')
            ax.grid(True, linestyle='--', alpha=0.7)
        
        # íŒŒì´ ì°¨íŠ¸
        colors = ['#4CAF50', '#2196F3', '#F44336']
        wedges, texts, autotexts = ax1.pie(grouped_data.values(), 
                                         labels=grouped_data.keys(), 
                                         autopct='%1.1f%%',
                                         colors=colors, 
                                         startangle=90,
                                         textprops={'fontsize': 12})
        ax1.set_title('í‘œì • ë¶„í¬', fontsize=14, pad=15)

        # ì‹œê°„ë³„ ê°ì • ë³€í™”
        timestamps = [r['timestamp'] for r in self.results]
        emotion_values = [self.emotion_weights[r['emotion']] for r in self.results]
        
        # 5-point ì´ë™ í‰ê· 
        if len(emotion_values) >= 5:
            moving_avg = np.convolve(emotion_values, np.ones(5), 'valid') / 5
            moving_timestamps = timestamps[2:-2]
            
            ax2.plot(timestamps, emotion_values, 'o-', alpha=0.3, label='ì‹¤ì œê°’')
            ax2.plot(moving_timestamps, moving_avg, 'r-', linewidth=2, label='ì´ë™í‰ê· ')
            ax2.axhline(y=70, color='green', linestyle='--', alpha=0.5, label='ì¤‘ë¦½ ê¸°ì¤€ì„ ')
            ax2.axhline(y=40, color='red', linestyle='--', alpha=0.5, label='ë¶€ì • ê¸°ì¤€ì„ ')
            ax2.set_xlabel('ì‹œê°„ (ì´ˆ)', fontsize=12)
            ax2.set_ylabel('í‘œì • ì ìˆ˜', fontsize=12)
            ax2.set_title('ì‹œê°„ë³„ í‘œì • ë³€í™”', fontsize=14, pad=15)
            ax2.legend(fontsize=10)
            ax2.grid(True, alpha=0.3)

        # ì‹ ë¢°ë„ ë¶„í¬
        confidences = [r['confidence'] for r in self.results]
        ax3.hist(confidences, bins=10, color='#9C27B0', alpha=0.7, edgecolor='black')
        ax3.axvline(x=self.thresholds['confidence_threshold'], color='red', linestyle='--',
                   label=f'ê¸°ì¤€ì„ : {self.thresholds["confidence_threshold"]}')
        ax3.set_xlabel('ì‹ ë¢°ë„', fontsize=12)
        ax3.set_ylabel('ë¹ˆë„', fontsize=12)
        ax3.set_title('í‘œì • ì¸ì‹ ì‹ ë¢°ë„', fontsize=14, pad=15)
        ax3.legend(fontsize=10)
        ax3.grid(True, alpha=0.3)

        # ì£¼ìš” ì§€í‘œ ë¹„êµ
        indicators = ['ì¤‘ë¦½ ë¹„ìœ¨', 'ê¸°ì¨ ë¹„ìœ¨', 'ì•ˆì •ì„±', 'ë¶€ì • ë¹„ìœ¨']
        current_values = [
            metrics['neutral_ratio'],
            metrics['happy_ratio'],
            metrics['stability_score'],
            metrics['negative_ratio']
        ]
        thresholds = [
            self.thresholds['neutral_ratio'],
            self.thresholds['happy_threshold'],
            0.7,  # ì•ˆì •ì„± ì„ê³„ê°’
            self.thresholds['negative_ratio']
        ]

        x = np.arange(len(indicators))
        width = 0.35
        
        ax4.bar(x - width/2, current_values, width, label='í˜„ì¬', color='#1976D2', alpha=0.8)
        ax4.bar(x + width/2, thresholds, width, label='ê¸°ì¤€', color='#FFA726', alpha=0.8)
        
        ax4.set_xlabel('ì§€í‘œ', fontsize=12)
        ax4.set_ylabel('ë¹„ìœ¨', fontsize=12)
        ax4.set_title('ì£¼ìš” ì§€í‘œ ë¹„êµ', fontsize=14, pad=15)
        ax4.set_xticks(x)
        ax4.set_xticklabels(indicators, fontsize=10)
        ax4.legend(fontsize=10)
        ax4.grid(True, alpha=0.3)

        # ì°¨íŠ¸ ì—¬ë°± ì¡°ì •
        plt.tight_layout()
        
        # ì°¨íŠ¸ ì €ì¥
        plt.savefig("webcam_analysis_result.png", dpi=200, bbox_inches='tight')
        plt.show()
        print("ğŸ“Š ë¶„ì„ ê²°ê³¼ ì°¨íŠ¸ê°€ 'webcam_analysis_result.png'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    analyzer = WebcamEmotionAnalyzer()
    
    print("ğŸ­ ì‹¤ì‹œê°„ ì›¹ìº  í‘œì • ë¶„ì„")
    print("=" * 50)
    print("â€¢ ì›¹ìº ì´ ì‹œì‘ë˜ë©´ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ì •ì´ ë¶„ì„ë©ë‹ˆë‹¤.")
    print("â€¢ ì¢…ë£Œí•˜ë ¤ë©´ 'q' í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”.")
    print("â€¢ ì¢…ë£Œ í›„ ë¶„ì„ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
    
    # í°íŠ¸ í™•ì¸
    font_path = get_font_path()
    if font_path:
        print(f"âœ“ í•œê¸€ í°íŠ¸ ì‚¬ìš©: {os.path.basename(font_path)}")
        # matplotlib í°íŠ¸ ì„¤ì •
        set_korean_font()
    else:
        print("âš ï¸ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    print("=" * 50)
    
    # ì›¹ìº  ë¶„ì„ ì‹¤í–‰
    results = analyzer.analyze_webcam()
    
    if results is None:
        print("\nâŒ ì›¹ìº  ë¶„ì„ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í‰ê°€ ìƒì„±
    assessment = analyzer.generate_assessment()
    
    print("\nğŸ“‹ ë¶„ì„ ê²°ê³¼")
    print("=" * 50)
    print(f"ğŸ’¯ ì¢…í•© ì ìˆ˜: {assessment['overall_score']}")
    print(f"ğŸ“Š ë“±ê¸‰: {assessment['grade']}")
    
    print("\nğŸ” ì£¼ìš” ë°œê²¬ì‚¬í•­:")
    for finding in assessment['key_findings']:
        print(f"   {finding}")
    
    if assessment['recommendations']:
        print("\nğŸ’¡ ê°œì„  ì œì•ˆ:")
        for rec in assessment['recommendations']:
            print(f"   {rec}")
    
    print("\nğŸ“ˆ ë¶„ì„ ì°¨íŠ¸ ìƒì„± ì¤‘...")
    analyzer.create_analysis_chart()
    
    print("\nâœ… ë¶„ì„ ì™„ë£Œ!")

if __name__ == "__main__":
    main() 