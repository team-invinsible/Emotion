import cv2
import numpy as np
import torch
import torchvision.transforms as transforms
from emotion import EmotionNet
from collections import Counter
from moviepy.editor import VideoFileClip
from PIL import Image
import argparse

# ëª¨ë¸ ë¡œë“œ
device = torch.device("cpu")
model = EmotionNet()

checkpoint = torch.load("model.pth", map_location=device)
model.load_state_dict(checkpoint['model'])
model.eval()

# ê°ì • í´ë˜ìŠ¤
class_labels = ['ê¸°ì¨', 'ë‹¹í™©', 'ë¶„ë…¸', 'ë¶ˆì•ˆ', 'ìƒì²˜', 'ìŠ¬í””', 'ì¤‘ë¦½']
class_labels_dict = {'ê¸°ì¨': 0, 'ë‹¹í™©': 1, 'ë¶„ë…¸': 2,
                     'ë¶ˆì•ˆ': 3, 'ìƒì²˜': 4, 'ìŠ¬í””': 5, 'ì¤‘ë¦½': 6}

# ê¸ì •/ë¶€ì • ê°ì • ì„¸íŠ¸ ì •ì˜
positive_set = {'ê¸°ì¨', 'ë‹¹í™©', 'ì¤‘ë¦½'}
negative_set = {'ìŠ¬í””', 'ë¶ˆì•ˆ', 'ë¶„ë…¸', 'ìƒì²˜'}

# ì˜ìƒ â†’ í”„ë ˆì„ â†’ ê°ì • ì¶”ë¡ 
def predict_emotions_from_video(video_path):
    clip = VideoFileClip(video_path)
    # results = [] # ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥í•˜ëŠ” ëŒ€ì‹  yield ì‚¬ìš©

    transform = transforms.Compose([
        transforms.Grayscale(num_output_channels=1),
        transforms.Resize((48, 48)),
        transforms.ToTensor(),
    ])

    for i, frame in enumerate(clip.iter_frames(fps=10)):  # ì´ˆë‹¹ 3í”„ë ˆì„
        image = Image.fromarray(frame)
        input_tensor = transform(image).unsqueeze(0)

        with torch.no_grad():
            output = model(input_tensor)
            probs = torch.nn.functional.softmax(output, dim=1)[0]
            pred_idx = torch.argmax(probs).item()
            pred_label = class_labels[pred_idx]
            score = probs[pred_idx].item()

        # results.append((pred_label, score)) # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ëŠ” ëŒ€ì‹  yield
        yield (pred_label, score) # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ yield

    # return results # ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ ëŒ€ì‹  generator ë°˜í™˜

# í‰ê°€ ë¡œì§
def evaluate_emotions(results):
    total = len(results)
    emotions = [r[0] for r in results]
    scores = dict((e, []) for e in class_labels)
    for label, score in results:
        scores[label].append(score)

    positive_count = sum([1 for e in emotions if e in positive_set])
    negative_count = sum([1 for e in emotions if e in negative_set])
    neutral_count = emotions.count("ì¤‘ë¦½")
    happy_scores = scores['ê¸°ì¨']

    transition_count = sum(1 for i in range(1, total) if emotions[i] != emotions[i-1])

    happy_score_avg = np.mean(happy_scores) if happy_scores else 0.0
    neutral_ratio = neutral_count / total
    positive_ratio = positive_count / total
    negative_ratio = negative_count / total

    forced_smile_penalty = -5 if happy_score_avg < 0.5 and negative_count > 0 else 0
    flat_penalty = -5 if neutral_ratio >= 0.9 else 0

    # ê°ì •ë³„ ê°€ì¤‘ì¹˜ ê¸°ë°˜ í‰ê°€ ì ìˆ˜ ê³„ì‚°
    emotion_weights = {
        "ê¸°ì¨": 1.0,
        "ë‹¹í™©": 0.8,
        "ì¤‘ë¦½": 0.5,
        "ìŠ¬í””": -0.8,
        "ë¶„ë…¸": -1.0,
        "ë¶ˆì•ˆ": -0.7,
        "ìƒì²˜": -0.6
    }
    emotion_score = sum(emotion_weights.get(e, 0) for e in emotions) / total

    # ê°ì • ë‹¤ì–‘ì„± ì ìˆ˜
    diversity_score = len(set(emotions)) / len(class_labels)

    # ê°ì • ì „ì´ í’ˆì§ˆ ë³´ë„ˆìŠ¤
    good_transitions = [('ë¶ˆì•ˆ', 'ê¸°ì¨'), ('ìŠ¬í””', 'ì¤‘ë¦½'), ('ì¤‘ë¦½', 'ê¸°ì¨')]
    transition_bonus = sum(
        2 for i in range(1, total)
        if (emotions[i-1], emotions[i]) in good_transitions
    )

    # ê°ì • ì¼ê´€ì„±
    emotion_count = Counter(emotions)
    most_common_emotion, freq = emotion_count.most_common(1)[0]
    consistency = freq / total

    # ìµœì¢… ì ìˆ˜ ê³„ì‚° (ê°œì„  ë²„ì „)
    score = (
        emotion_score * 25 +
        consistency * 5 +
        diversity_score * 10 +
        transition_bonus +
        happy_score_avg * 10 +
        forced_smile_penalty +
        flat_penalty
    )

    # ë“±ê¸‰ íŒì •
    if score >= 85:
        grade = "A"
    elif score >= 70:
        grade = "B"
    else:
        grade = "C"

    return {
        "ì ìˆ˜": round(score, 2),
        "ë“±ê¸‰": grade,
        "ê¸ì • ë¹„ìœ¨": round(positive_ratio * 100, 1),
        "ë¶€ì • ë¹„ìœ¨": round(negative_ratio * 100, 1),
        "ê¸°ì¨ í‰ê·  score": round(happy_score_avg, 3),
        "ì¤‘ë¦½ ë¹„ìœ¨": round(neutral_ratio * 100, 1),
        "ê°ì • ì „ì´ ìˆ˜": transition_count,
        "forced smile ê°ì ": forced_smile_penalty,
        "flat ê°ì • ê°ì ": flat_penalty
    }

import matplotlib.pyplot as plt

def plot_emotion_timeline(results):
    emotion_colors = {
        'ê¸°ì¨': 'gold',
        'ìŠ¬í””': 'blue',
        'ì¤‘ë¦½': 'gray',
        'ë¶„ë…¸': 'red',
        'ë¶ˆì•ˆ': 'purple',
        'ìƒì²˜': 'brown',
        'ë‹¹í™©': 'green',
        'ë¶„ë…¸': 'black',
        'ìƒì²˜': 'darkgreen'
    }

    frame_idx = list(range(len(results)))
    emotion_labels = [e[0] for e in results]
    emotion_scores = [e[1] for e in results]
    colors = [emotion_colors.get(label, 'black') for label in emotion_labels]

    plt.figure(figsize=(12, 5))
    plt.scatter(frame_idx, emotion_scores, c=colors, s=100, edgecolors='k', alpha=0.8)
    plt.plot(frame_idx, emotion_scores, linestyle='--', color='lightgray', alpha=0.6)

    for i, label in enumerate(emotion_labels):
        plt.text(frame_idx[i], emotion_scores[i] + 0.02, label, ha='center', fontsize=9)

    plt.ylim(0, 1.05)
    plt.xlabel("Frame Number (sec * 3)")
    plt.ylabel("Emotion score (%)")
    plt.title("Emotion Predict")
    plt.grid(True)
    plt.tight_layout()
    plt.savefig("emotion_timeline.png")
    plt.show()
    print("âœ… ê°ì • íƒ€ì„ë¼ì¸ ê·¸ë˜í”„ê°€ 'emotion_timeline.png'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    # ëª…ë ¹í–‰ ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(description='ë©´ì ‘ ì˜ìƒ í‘œì • ë¶„ì„')
    parser.add_argument('video_path', help='ë¶„ì„í•  ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ')
    args = parser.parse_args()

    all_results = [] # ì „ì²´ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    print(f"ë¹„ë””ì˜¤ íŒŒì¼ ë¶„ì„ ì¤‘: {args.video_path}")
    print("=" * 50)
    
    try:
        print("ë¹„ë””ì˜¤ í”„ë ˆì„ë³„ ê°ì • ì˜ˆì¸¡ ê²°ê³¼:")
        for i, (label, score) in enumerate(predict_emotions_from_video(args.video_path)):
            all_results.append((label, score))
            if i % 10 == 0:  # 10í”„ë ˆì„ë§ˆë‹¤ ì§„í–‰ìƒí™© ì¶œë ¥
                print(f"í”„ë ˆì„ {i+1}: {label} (Score: {score:.3f})")

        print("\nì „ì²´ ë¹„ë””ì˜¤ í‰ê°€ ê²°ê³¼:")
        report = evaluate_emotions(all_results)

        print("\nğŸ“‹ ë¶„ì„ ê²°ê³¼")
        print("=" * 50)
        for k, v in report.items():
            print(f"{k}: {v}")

        print("\nğŸ“ˆ ê°ì • íƒ€ì„ë¼ì¸ ì°¨íŠ¸ ìƒì„± ì¤‘...")
        plot_emotion_timeline(all_results)
        
        print("\nâœ… ë¶„ì„ ì™„ë£Œ!")
        
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: '{args.video_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")